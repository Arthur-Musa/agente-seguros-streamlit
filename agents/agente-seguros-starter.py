import streamlit as st
from langchain_anthropic import ChatAnthropic
from langchain.memory import ConversationBufferMemory
import os

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Central de Agentes - Seguradora", layout="wide")

# T√≠tulo e sele√ß√£o de agente
st.title("üè¢ Central de Agentes Aut√¥nomos")
col1, col2 = st.columns([1, 3])

with col1:
    agente_selecionado = st.selectbox(
        "Escolha o Agente:",
        ["Analista de Risco", "Atendimento ao Cliente", "Processador de Sinistros", 
         "Consultor de Produtos", "Compliance"]
    )

# Configurar personalidade baseada no agente
personalidades = {
    "Analista de Risco": """Voc√™ √© um analista de risco especializado em seguros.
    Suas habilidades incluem: an√°lise de dados, scoring de risco, detec√ß√£o de padr√µes.
    Responda de forma t√©cnica mas clara.""",
    
    "Atendimento ao Cliente": """Voc√™ √© um assistente de atendimento especializado em seguros.
    Suas habilidades incluem: explicar coberturas, tirar d√∫vidas sobre ap√≥lices, auxiliar em cota√ß√µes.
    Use linguagem simples e acess√≠vel.""",
    
    "Processador de Sinistros": """Voc√™ √© um especialista em processamento de sinistros.
    Suas habilidades incluem: an√°lise de documentos, estimativa de danos, detec√ß√£o de fraudes.
    Seja objetivo e procedimental.""",
    
    "Consultor de Produtos": """Voc√™ √© um consultor especializado em produtos de seguro.
    Suas habilidades incluem: recomendar produtos, personalizar coberturas, identificar oportunidades.
    Seja consultivo e focado nas necessidades do cliente.""",
    
    "Compliance": """Voc√™ √© um analista de compliance para seguradoras.
    Suas habilidades incluem: verificar conformidade, monitorar regula√ß√µes, gerar relat√≥rios.
    Seja preciso e cite regulamenta√ß√µes quando relevante."""
}

# Inicializar mem√≥ria e chat
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory()
    st.session_state.messages = []

# √Årea principal de chat
with col2:
    st.subheader(f"üí¨ Conversando com: {agente_selecionado}")
    
    # Container para mensagens
    chat_container = st.container()
    
    # Exibir hist√≥rico
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
    
    # Input do usu√°rio
    if prompt := st.chat_input("Digite sua mensagem..."):
        # Adicionar mensagem do usu√°rio
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # Configurar LLM com personalidade
        llm = ChatAnthropic(
            model="claude-3-sonnet-20240229",
            temperature=0.3,
            api_key=os.getenv("ANTHROPIC_API_KEY")
        )
        
        # Criar prompt com contexto
        system_prompt = personalidades[agente_selecionado]
        full_prompt = f"{system_prompt}\n\nUsu√°rio: {prompt}\nAssistente:"
        
        # Gerar resposta
        with st.spinner("Processando..."):
            response = llm.invoke(full_prompt)
            response_text = response.content
            
            # Adicionar resposta ao hist√≥rico
            st.session_state.messages.append({"role": "assistant", "content": response_text})
            
            # Rerun para atualizar o chat
            st.rerun()

# Barra lateral com informa√ß√µes
with st.sidebar:
    st.header("üìä Painel de Controle")
    st.metric("Conversas Hoje", "147")
    st.metric("Tempo M√©dio Resposta", "2.3s")
    st.metric("Satisfa√ß√£o", "94%")
    
    st.divider()
    
    st.header("üîß Configura√ß√µes")
    if st.button("Limpar Conversa"):
        st.session_state.messages = []
        st.session_state.memory = ConversationBufferMemory()
        st.rerun()
    
    st.divider()
    
    st.info("""
    **Capacidades do Agente:**
    - Processamento em tempo real
    - Integra√ß√£o com bases de dados
    - An√°lise de documentos
    - Gera√ß√£o de relat√≥rios
    """)
